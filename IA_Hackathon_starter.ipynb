{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon at Semana Franco-Mexicana de IA"
      ],
      "metadata": {
        "id": "dcMawhgqvAWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is intended to give a starting point for your own work, either in data storytelling or prediction. You can use this notebook from Gooogle Colab or locally in a jupyter server."
      ],
      "metadata": {
        "id": "0IzhdF76vDJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions for Google Colab"
      ],
      "metadata": {
        "id": "NVV2Jligvt-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, download the github repository. Only execute these lines **once**:"
      ],
      "metadata": {
        "id": "FXar-z8AvQYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jbhayet/semanaia-hackathon/"
      ],
      "metadata": {
        "id": "8aCKAEzYvU_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd semanaia-hackathon"
      ],
      "metadata": {
        "id": "408mic0FvaK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On Colab, you should have all of the necessary python packages already installed, so you can go directly to the \"Loading the data\" section."
      ],
      "metadata": {
        "id": "neS078IPyEyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instructions for local utilisation"
      ],
      "metadata": {
        "id": "6D3NFlr1v3CX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run this notebook locally, you should first download the repository through the Github interface or by doing the following in a shell like [bash for Linux](https://ubuntu.com/tutorials/command-line-for-beginners#1-overview) or [git for Windows](https://gitforwindows.org/):"
      ],
      "metadata": {
        "id": "vZgOGPBYwhI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "git clone https://github.com/jbhayet/semanaia-hackathon/\n",
        "cd semania-hackathon\n",
        "```"
      ],
      "metadata": {
        "id": "vTJNaZNQxH9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then you will need to install the python libraries for this repository. If you don't have a python environment installed, you can use [anaconda](https://www.anaconda.com/) to create one. Once you are in a python environment, you can install the libraries of this repository by doing:"
      ],
      "metadata": {
        "id": "doQEjDt-xUrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```bash\n",
        "pip install --upgrade pip\n",
        "pip install -r requirements.txt\n",
        "```"
      ],
      "metadata": {
        "id": "qzLD2_w7xr4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data"
      ],
      "metadata": {
        "id": "jxblG5QtvouO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will first load some of the python packages we will use in this notebook. If this line doesn't work (it outputs an error), go back to one of the previous steps."
      ],
      "metadata": {
        "id": "k9FCaLXYyd2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "lt4HaHBQxQwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the repository is downloaded and the python environment installed, you should load the data and check that it is valid. We will start with the training data from Mexico City:"
      ],
      "metadata": {
        "id": "JkZQdZrWxRmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cdmx_file = 'data/cdmx_data_series.csv'\n",
        "print(f\"--- Reading train data from {cdmx_file}\")\n",
        "data_cdmx = pd.read_csv(cdmx_file)\n",
        "print(f\"--- Read {len(data_cdmx)} records\")"
      ],
      "metadata": {
        "id": "tzkFIP3pyt4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will look at the first few rows of the data in order to validate that they were properly loaded:"
      ],
      "metadata": {
        "id": "Sn7S4rSMzoyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_cdmx.head()"
      ],
      "metadata": {
        "id": "INb7_sh4y2rf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will load the data from Lyon in the same way:"
      ],
      "metadata": {
        "id": "QweTq7VmzvW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyon_file = 'data/lyon_data_series.csv'\n",
        "print(f\"--- Reading train data from {lyon_file}\")\n",
        "data_lyon = pd.read_csv(lyon_file)\n",
        "print(f\"--- Read {len(data_lyon)} records\")"
      ],
      "metadata": {
        "id": "S5rYw1Mgy6GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_lyon.head()"
      ],
      "metadata": {
        "id": "whdzbypM0J9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, there is a different amount of data for Lyon and Mexico City, but they have the same fields. Your task is to explore or predict the different levels of station usage, which are represented as relative values from midnight each day in the `occupation_x` columns, where `x` is the hour. Depending on if you want to work on data storytelling or prediction, you can use the following sections as starting points."
      ],
      "metadata": {
        "id": "y3j-qo0P0Zsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Storytelling"
      ],
      "metadata": {
        "id": "tJygC7MA0X7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Storytelling is about understanding the data through visualizations and analysis. What trends do you see in the data? How can they be used to inform a decision? Are any of the data suspect or not complete? How could the dataset be improved? All of these questions can be answered through a full understanding of the data. Here is an example visualization to start with. This visualization shows the average value of occupation per hour, each day of the week in Lyon. Can you change this code to make the same visualization for Mexico City?"
      ],
      "metadata": {
        "id": "a3juJjuP9ggv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Define day names for better labels\n",
        "day_names = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
        "\n",
        "# Create figure with subplots\n",
        "fig, axes = plt.subplots(2, 4, figsize=(12, 6))  # 2x4 grid for 7 days + 1 empty\n",
        "axes = axes.flatten()  # Flatten for easier indexing\n",
        "\n",
        "# Hide the 8th subplot since we only have 7 days\n",
        "axes[7].set_visible(False)\n",
        "\n",
        "# Create occupation columns list\n",
        "occupation_cols = [f'occupation_{i}' for i in range(24)]\n",
        "\n",
        "# Process each day of the week\n",
        "for day in range(7):\n",
        "    # Filter data for this specific weekday\n",
        "    day_data = data_lyon[data_lyon['weekday'] == day]\n",
        "\n",
        "    if len(day_data) == 0:\n",
        "        axes[day].text(0.5, 0.5, f'No data for {day_names[day]}',\n",
        "                      ha='center', va='center', transform=axes[day].transAxes)\n",
        "        axes[day].set_title(f'{day_names[day]} (No Data)')\n",
        "        continue\n",
        "\n",
        "    # Calculate average occupation for each hour\n",
        "    hourly_avg = day_data[occupation_cols].mean()\n",
        "\n",
        "    # Create the plot\n",
        "    hours = range(24)\n",
        "    axes[day].plot(hours, hourly_avg.values, marker='o', linewidth=2, markersize=4)\n",
        "    axes[day].set_title(f'{day_names[day]} (n={len(day_data):,})', fontsize=12, fontweight='bold')\n",
        "    axes[day].set_xlabel('Hour of Day')\n",
        "    axes[day].set_ylabel('Average Occupation')\n",
        "    axes[day].grid(True, alpha=0.3)\n",
        "    axes[day].set_xlim(0, 23)\n",
        "    axes[day].set_xticks(range(0, 24, 4))  # Show every 4 hours\n",
        "\n",
        "    # Add some styling\n",
        "    axes[day].fill_between(hours, hourly_avg.values, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Average Bike Station Occupation Patterns by Day of Week in Lyon',\n",
        "              fontsize=16, fontweight='bold', y=1.02);"
      ],
      "metadata": {
        "id": "Q6NJSbnT0OpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To go further, look at the `generate_zones.py` notebook, which loads the geographic data. The different areas have very different bike uses, so visualizing these data on a map can give much better understanding."
      ],
      "metadata": {
        "id": "mM8IwrZ9_RsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "1OJjLYu2AXZo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the prediction task, we"
      ],
      "metadata": {
        "id": "99pzpy_iAZNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_hour = 15\n",
        "df = data_lyon\n",
        "\n",
        "# Define features: static info + weather + previous occupation levels\n",
        "feature_cols = [\n",
        "    'lon', 'lat', 'zone_id',           # Location features\n",
        "    'tmin', 'tmax', 'prcp', 'wspd',    # Weather features\n",
        "    'weekday', 'holiday'               # Time features\n",
        "]\n",
        "\n",
        "# Add previous occupation levels (from hour 0 to current_hour)\n",
        "prev_occupation_cols = [f'occupation_{i}' for i in range(current_hour + 1)]\n",
        "feature_cols.extend(prev_occupation_cols)\n",
        "\n",
        "# Target: next 3 hours of occupation\n",
        "target_cols = [f'occupation_{current_hour + i}' for i in range(1, 4)]\n",
        "\n",
        "# Create feature matrix and target matrix\n",
        "X = df[feature_cols].copy()\n",
        "y = df[target_cols].copy()\n",
        "\n",
        "# Add hour of day as feature\n",
        "X['current_hour'] = current_hour\n",
        "\n",
        "print(f\"Dataset shape: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "print(f\"Predicting hours {current_hour+1}, {current_hour+2}, {current_hour+3}\")"
      ],
      "metadata": {
        "id": "1Og6OYKe1LKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will separate the data into two parts: a training dataset to train the model, and a test dataset to evaluate the model."
      ],
      "metadata": {
        "id": "5NJD_AzqDWdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training dataset shape: {X_train.shape[0]} samples, {X_train.shape[1]} features\")\n",
        "print(f\"Test dataset shape: {X_test.shape[0]} samples, {X_test.shape[1]} features\")"
      ],
      "metadata": {
        "id": "Tn8KXnrlBjAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have defined our input data `X` and our target `y`, and split them into training and test data, we can train a machine learning model on the training data to predict the target."
      ],
      "metadata": {
        "id": "V7txTP4lCQ1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model (MultiOutputRegressor handles multiple targets)\n",
        "from sklearn.multioutput import MultiOutputRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "model = MultiOutputRegressor(\n",
        "    RandomForestRegressor(\n",
        "        n_estimators=10,\n",
        "        max_depth=3,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        ")\n",
        "\n",
        "print(\"Training model...\")\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "5ChejeXeCnwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will evaluate the model on the test data. Here we evaluate the model using the Mean Absolute Error and the R2 score."
      ],
      "metadata": {
        "id": "A4gU2WcADZC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Performance:\")\n",
        "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "Fl0PxGgZDYG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To go further, apply your model to the data in Mexico City. Does it work as well? Then, consider your prediciton model's data. Does it work for hours besides 3pm? Try training it so that it can predict any 3 hour period, not just from 3pm."
      ],
      "metadata": {
        "id": "2rQVAELvDwlX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EZbIGWMELOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}